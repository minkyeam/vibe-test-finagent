from fastapi import FastAPI
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import yfinance as yf
import os
import asyncio
import requests as _requests
from datetime import datetime
from typing import Optional, List
import time
import pytz
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.output_parsers import StrOutputParser
# Load environment variables
load_dotenv()

# yfinance ì„¸ì…˜ ì„¤ì • (Vercel ë“± í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œ ì°¨ë‹¨ ë°©ì§€)
import requests as req_lib
_session = req_lib.Session()
_session.headers.update({'User-Agent': 'Mozilla/5.0 FinAgent/1.0'})

app = FastAPI()

# â”€â”€ In-memory cache for market data (60s TTL) â”€â”€
_market_cache: dict = {"data": None, "signals": None, "fetched_at": 0}
CACHE_TTL = 60  # seconds

# â”€â”€ In-memory cache for FRED liquidity data (6h TTL) â”€â”€
_liquidity_cache: dict = {"data": None, "fetched_at": 0}
LIQUIDITY_CACHE_TTL = 6 * 3600  # 6ì‹œê°„ (FREDëŠ” ì¼/ì£¼ ë‹¨ìœ„ ì—…ë°ì´íŠ¸)

# â”€â”€ RAG: Load institutional reports once at startup â”€â”€
_institutional_context: str = "No specific reports available."
try:
    _report_path = os.path.join(os.path.dirname(__file__), "data", "institutional_reports.json")
    if os.path.exists(_report_path):
        with open(_report_path, "r", encoding="utf-8") as _f:
            _report_data = json.load(_f)
            _institutional_context = "\n\n".join([
                f"[{r['institution']} - {r['title']}]\nSummary: {r['summary']}\nDetails: {r['content']}"
                for r in _report_data.get("reports", [])
            ])
        print(f"[RAG] Loaded {len(_report_data.get('reports', []))} institutional reports.")
except Exception as _rag_e:
    print(f"[RAG] Load error: {_rag_e}")


class MarketData(BaseModel):
    symbol: str
    price: float
    change_percent: float
    name: str


@app.get("/api/health")
@app.get("/health")
@app.get("/")
def read_root():
    return {
        "status": "online",
        "message": "Financial Macro Agent API is running",
        "timestamp": datetime.now().isoformat()
    }


def fetch_market_data_internal():
    symbols = {
        "KRW=X": "USD/KRW",
        "^KS11": "KOSPI",
        "^KQ11": "KOSDAQ",
        "^TNX": "US 10Y Bond",
        "^IRX": "US 13W Bond",
        "CL=F": "WTI Oil",
        "GC=F": "Gold",
        "BTC-USD": "Bitcoin",
        "ETH-USD": "Ethereum",
        "005930.KS": "Samsung Elec",
        "DX-Y.NYB": "Dollar Index",
    }

    data = []
    signals = []

    try:
        # yf.downloadì— ì„¸ì…˜ ì „ë‹¬
        ticker_list = list(symbols.keys())
        df = yf.download(ticker_list, period="2d", interval="1d", group_by='ticker', silent=True, session=_session)
        
        for symbol, name in symbols.items():
            try:
                if symbol not in df.columns.levels[0]: continue
                hist = df[symbol]
                if hist.empty or len(hist) < 1: continue
                
                current = hist['Close'].iloc[-1]
                prev = hist['Close'].iloc[-2] if len(hist) > 1 else current
                change = ((current - prev) / prev) * 100 if prev != 0 else 0
                
                data.append({
                    "symbol": symbol,
                    "name": name,
                    "price": round(float(current), 2),
                    "change_percent": round(float(change), 2)
                })
            except Exception:
                continue
    except Exception as e:
        print(f"Error in batch fetching: {e}")

    return {"data": data, "signals": signals}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# â—€ ì—°ì¤€ / ì¬ë¬´ë¶€ ìœ ë™ì„± ì§€í‘œ (FRED ë¬´ë£Œ ê³µê°œ API)    #
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

FRED_LIQUIDITY_SERIES = {
    # ì—°ì¤€ ëŒ€ì°¨ëŒ€ì¡°í‘œ (QT/QE êµ¬ë¶„ í•µì‹¬) â€” ë‹¨ìœ„: ë°±ë§Œë‹¬ëŸ¬ â†’ 10ì–µë‹¬ëŸ¬($B)ë¡œ ë³€í™˜
    "WALCL":     {"name": "Fed Balance Sheet",         "unit": "$B",  "scale": 1e-3,  "desc": "ì—°ì¤€ ì´ìì‚° â€” QT/QE íŒë‹¨ í•µì‹¬ ì§€í‘œ"},
    # ON RRP â€” ë‹¨ê¸° ìœ ë™ì„± í†µì œ í†µë¡œ â€” ë‹¨ìœ„: 10ì–µë‹¬ëŸ¬($B)
    "RRPONTSYD": {"name": "ON RRP Balance",            "unit": "$B",  "scale": 1.0,  "desc": "ì—°ì¤€ ì—­ë ˆí¬ ì”ê³  (ë‹¨ê¸° ìœ ë™ì„± í¡ìˆ˜ëŸ‰)"},
    # TGA â€” ì¬ë¬´ë¶€ ì¼ë°˜ê³„ì¢Œ â€” ë‹¨ìœ„: ë°±ë§Œë‹¬ëŸ¬($M)
    "WTREGEN":   {"name": "Treasury General Account",  "unit": "$M",  "scale": 1.0,  "desc": "ì¬ë¬´ë¶€ TGA ì”ì•¡ â€” êµ­ì±„ ë°œí–‰Â·ìƒí™˜ ì‹œ ìœ ë™ì„± ì˜í–¥"},
    # SOFR â€” LIBOR ëŒ€ì²´ ê¸°ì¤€ê¸ˆë¦¬ â€” ë‹¨ìœ„: %
    "SOFR":      {"name": "SOFR Rate",                 "unit": "%",   "scale": 1.0,  "desc": "ë‹¨ê¸° ë‹´ë³´ë¶€ ê¸°ì¤€ê¸ˆë¦¬ (LIBOR ëŒ€ì²´)"},
    # ì‹¤íš¨ ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ â€” ë‹¨ìœ„: %
    "DFF":       {"name": "Effective Fed Funds Rate",  "unit": "%",   "scale": 1.0,  "desc": "ì‹¤íš¨ ì—°ë°©ê¸°ê¸ˆê¸ˆë¦¬ (FOMC ì •ì±… ë°˜ì˜)"},
    # M2 í†µí™”ëŸ‰ â€” ë‹¨ìœ„: 10ì–µë‹¬ëŸ¬($B)
    "M2SL":      {"name": "M2 Money Supply",           "unit": "$B",  "scale": 1.0,  "desc": "M2 ê´‘ì˜ í†µí™”ëŸ‰ (ì‹œì¤‘ ìœ ë™ì„± ì´ëŸ‰)"},
}


def fetch_fred_series(series_id: str):
    """FRED ê³µê°œ CSV ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ìµœì‹ ê°’ 1ê°œ ë°˜í™˜. API í‚¤ ë¶ˆí•„ìš”."""
    try:
        url = f"https://fred.stlouisfed.org/graph/fredgraph.csv?id={series_id}"
        resp = _requests.get(url, timeout=10,
                             headers={"User-Agent": "Mozilla/5.0 FinAgent/1.0"})
        resp.raise_for_status()
        lines = [l for l in resp.text.strip().splitlines() if l and not l.startswith("DATE")]
        last_line = lines[-1]  # ìµœì‹  ë°ì´í„°
        date_str, value_str = last_line.split(",")
        if value_str.strip() in ("", "."):  # ëˆ„ë½ê°’
            # ëˆ„ë½ê°’ì´ë©´ ì´ì „ ë°ì´í„° ì°¾ê¸°
            for line in reversed(lines):
                d, v = line.split(",")
                if v.strip() not in ("", "."):
                    return float(v.strip()), d.strip()
            return None, None
        return float(value_str.strip()), date_str.strip()
    except Exception as e:
        print(f"[FRED] Error fetching {series_id}: {e}")
        return None, None


def fetch_liquidity_data() -> List[dict]:
    """FRED 6ê°œ ì§€í‘œ íŒ¨ì¹˜ íš¨ì¹˜."""
    results = []
    for series_id, meta in FRED_LIQUIDITY_SERIES.items():
        value, date = fetch_fred_series(series_id)
        if value is not None:
            scaled = value * meta["scale"]
            results.append({
                "series": series_id,
                "name": meta["name"],
                "value": round(scaled, 2),
                "unit": meta["unit"],
                "date": date,
                "desc": meta["desc"],
            })
            print(f"[FRED] {series_id}: {scaled:.2f} {meta['unit']} ({date})")
        else:
            print(f"[FRED] {series_id}: N/A")
    return results


def _get_cached_liquidity() -> List[dict]:
    """FRED ìœ ë™ì„± ë°ì´í„° ì¼€ì‹œ (6h TTL)."""
    global _liquidity_cache
    now = time.time()
    if _liquidity_cache["data"] is not None and (now - _liquidity_cache["fetched_at"]) < LIQUIDITY_CACHE_TTL:
        print(f"[Liquidity Cache HIT] age={(now - _liquidity_cache['fetched_at'])/3600:.1f}h")
        return _liquidity_cache["data"]
    print("[Liquidity Cache MISS] Fetching FRED liquidity data...")
    _liquidity_cache["data"] = fetch_liquidity_data()
    _liquidity_cache["fetched_at"] = now
    return _liquidity_cache["data"]


def _get_cached_market_data() -> dict:
    """ìºì‹œëœ ì‹œì¥ ë°ì´í„° ë°˜í™˜. ë§Œë£Œ ì‹œ ìƒˆë¡œ fetch."""
    global _market_cache
    now = time.time()
    if _market_cache["data"] is not None and (now - _market_cache["fetched_at"]) < CACHE_TTL:
        print(f"[Cache HIT] age={(now - _market_cache['fetched_at']):.1f}s")
        return _market_cache
    print("[Cache MISS] Fetching fresh market data...")
    result = fetch_market_data_internal()
    _market_cache["data"] = result["data"]
    _market_cache["signals"] = result["signals"]
    _market_cache["fetched_at"] = now
    return _market_cache


@app.get("/api/market-data")
@app.get("/market-data")
def get_market_data():
    try:
        cached = _get_cached_market_data()
        return {"data": cached["data"]}
    except Exception as e:
        print(f"[API ERROR] market-data: {e}")
        return {"data": [], "error": str(e)}


@app.get("/api/liquidity")
@app.get("/liquidity")
def get_liquidity_data():
    """ì—°ì¤€/ì¬ë¬´ë¶€ ìœ ë™ì„± ì§€í‘œ ë°˜í™˜."""
    try:
        data = _get_cached_liquidity()
        return {"data": data}
    except Exception as e:
        print(f"[API ERROR] liquidity: {e}")
        return {"data": [], "error": str(e)}


class AnalysisRequest(BaseModel):
    query: str
    model: str = "gemini"


@app.post("/api/analyze")
async def analyze_macro(request: AnalysisRequest):
    api_key_openai = os.getenv("OPENAI_API_KEY")
    api_key_google = os.getenv("GOOGLE_API_KEY")
    api_key_anthropic = os.getenv("ANTHROPIC_API_KEY")

    llm = None
    model_source = "Unknown"
    requested_model = request.model.lower()

    # â”€â”€ ëª¨ë¸ êµ¬ì„±: ê¸°ë³¸ + Provider ë‚´ë¶€ Fallback â”€â”€
    # Gemini: 2.0-flash â†’ 1.5-flash-8b
    # GPT:    gpt-4o    â†’ gpt-4o-mini
    # Claude: 3.5-sonnet â†’ 3.5-haiku

    GEMINI_MODELS = [
        ("gemini-2.0-flash",        "Google Gemini 2.0 Flash"),
        ("gemini-flash-lite-latest", "Google Gemini Flash Lite (Fallback)"),
    ]
    GPT_MODELS = [
        ("gpt-4o",                 "OpenAI GPT-4o"),
        ("gpt-4o-mini",            "OpenAI GPT-4o Mini (Fallback)"),
    ]
    CLAUDE_MODELS = [
        ("claude-3-5-sonnet-20241022", "Anthropic Claude 3.5 Sonnet"),
        ("claude-3-5-haiku-20241022",  "Anthropic Claude 3.5 Haiku (Fallback)"),
    ]

    def _is_retryable_error(msg: str) -> bool:
        keywords = ["429", "quota", "resourceexhausted", "rate_limit",
                    "rate limit", "too many requests", "overloaded",
                    "credit", "billing", "insufficient_quota", "503", "demand"]
        m = msg.lower()
        return any(k in m for k in keywords)

    def _build_gemini(model_id: str):
        from langchain_google_genai import ChatGoogleGenerativeAI
        return ChatGoogleGenerativeAI(
            model=model_id,
            google_api_key=api_key_google,
            temperature=0.7,
            max_retries=0,  # langchain ë‚´ë¶€ retry ë¹„í™œì„±í™” â†’ ì¦‰ì‹œ ì—ëŸ¬ ì „íŒŒ
        )

    def _build_gpt(model_id: str):
        return ChatOpenAI(
            temperature=0.7,
            model_name=model_id,
            openai_api_key=api_key_openai,
            max_retries=0,
        )

    def _build_claude(model_id: str):
        from langchain_anthropic import ChatAnthropic
        return ChatAnthropic(
            model=model_id,
            anthropic_api_key=api_key_anthropic,
            temperature=0.7,
            max_tokens=8096,
            max_retries=0,
        )

    # ì„ íƒëœ providerì˜ ëª¨ë¸ ëª©ë¡ê³¼ ë¹Œë” ê²°ì •
    if "gemini" in requested_model:
        if not api_key_google:
            async def _err():
                yield "> âš ï¸ **Google API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.** `.env`ì— `GOOGLE_API_KEY`ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”."
            return StreamingResponse(_err(), media_type="text/plain")
        model_candidates = GEMINI_MODELS
        model_builder = _build_gemini

    elif "gpt" in requested_model or "openai" in requested_model:
        if not api_key_openai:
            async def _err():
                yield "> âš ï¸ **OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.** `.env`ì— `OPENAI_API_KEY`ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”."
            return StreamingResponse(_err(), media_type="text/plain")
        model_candidates = GPT_MODELS
        model_builder = _build_gpt

    elif "claude" in requested_model:
        if not api_key_anthropic:
            async def _err():
                yield "> âš ï¸ **Anthropic API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.** `.env`ì— `ANTHROPIC_API_KEY`ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”."
            return StreamingResponse(_err(), media_type="text/plain")
        model_candidates = CLAUDE_MODELS
        model_builder = _build_claude

    else:
        async def _err():
            yield f"> âš ï¸ **ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸**: `{request.model}`. gemini / gpt / claude ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."
        return StreamingResponse(_err(), media_type="text/plain")

    # â”€â”€ 1. ì‹œì¥ ë°ì´í„° + ìœ ë™ì„± ë°ì´í„°: ë³‘ë ¬ fetch â”€â”€
    try:
        # ì‹œì¥ ë°ì´í„°ì™€ ìœ ë™ì„± ë°ì´í„°ë¥¼ ë™ì‹œ fetchfetch
        loop = asyncio.get_event_loop()
        cached_task = loop.run_in_executor(None, _get_cached_market_data)
        liquidity_task = loop.run_in_executor(None, _get_cached_liquidity)
        cached, liquidity_data = await asyncio.gather(cached_task, liquidity_task)

        market_data = cached["data"]
        macro_signals = "\n".join(cached["signals"] or [])
        market_str = "\n".join([
            f"{item['name']} ({item['symbol']}): {item['price']} ({item['change_percent']}%) [Momentum: {item.get('momentum', 'N/A')}]"
            for item in market_data
        ])
        print(f"[Market] {len(market_data)} items | [Liquidity] {len(liquidity_data)} indicators")

        # ìœ ë™ì„± ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ ì¡°ë¦½
        if liquidity_data:
            liquidity_context = "\n".join([
                f"{item['name']} ({item['series']}): {item['value']:,.2f} {item['unit']}  [{item['date']}]  â€” {item['desc']}"
                for item in liquidity_data
            ])
        else:
            liquidity_context = "FRED ìœ ë™ì„± ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    except Exception as e:
        import traceback; traceback.print_exc()
        async def _err():
            yield f"> âš ï¸ **ì‹œì¥ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨**: {str(e)}"
        return StreamingResponse(_err(), media_type="text/plain")

    # â”€â”€ 2. ê²€ìƒ‰: asyncio.gatherë¡œ ë³‘ë ¬ ì‹¤í–‰ â”€â”€
    user_query = request.query

    async def _search(q: str) -> str:
        try:
            loop = asyncio.get_event_loop()
            search = DuckDuckGoSearchRun()
            return await loop.run_in_executor(None, search.run, q)
        except Exception as e:
            print(f"[Search WARN] '{q[:30]}': {e}")
            return "Data unavailable."

    print("[Search] Starting parallel DuckDuckGo searches...")
    results = await asyncio.gather(
        _search(f"{user_query} ìµœì‹  ê¸€ë¡œë²Œ ê¸ˆìœµ ë‰´ìŠ¤ ê²½ì œ ë¶„ì„ 2025"),
        _search("í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬ ê²°ì • ìµœì‹  í†µí™”ì •ì±… 2025"),
        _search("Federal Reserve FOMC meeting outcome interest rate decision 2025"),
        _search("US CPI inflation PCE core 2025 latest"),
        _search("í•œêµ­ ë°˜ë„ì²´ ìˆ˜ì¶œ ë™í–¥ 2025"),
    )
    news_summary, bok_policy, fed_policy, cpi_signal, semi_signal = results
    macro_signals += f"\n{cpi_signal}\n{semi_signal}"
    print("[Search] All parallel searches done.")

    # â”€â”€ 3. LLM ìŠ¤íŠ¸ë¦¬ë° (Provider ë‚´ë¶€ Fallback í¬í•¨) â”€â”€
    chain_inputs = {
        "market_data": market_str,
        "news_summary": news_summary,
        "bok_policy": bok_policy,
        "fed_policy": fed_policy,
        "macro_signals": macro_signals,
        "institutional_context": _institutional_context,
        "liquidity_context": liquidity_context,
        "user_query": user_query,
    }

    async def generate():
        for attempt, (model_id, model_label) in enumerate(model_candidates):
            is_fallback = attempt > 0
            llm = model_builder(model_id)
            chain = MACRO_ANALYSIS_PROMPT | llm | StrOutputParser()
            print(f"[LLM] Streaming with {model_label} (attempt {attempt + 1})...")

            # fallback ì‹œ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
            if is_fallback:
                yield f"\n\n> âš¡ **{model_label}** ë¡œ ìë™ ì „í™˜í•˜ì—¬ ì¬ì‹œë„í•©ë‹ˆë‹¤.\n\n"
            else:
                yield f"**[{model_label}]**\n\n"

            try:
                accumulated = ""
                async for chunk in chain.astream(chain_inputs):
                    accumulated += chunk
                    yield chunk
                # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ â€” ì„±ê³µ
                print(f"[LLM] Done. model={model_label}, chars={len(accumulated)}")
                return

            except Exception as e:
                err_msg = str(e)
                print(f"[LLM Error] {model_label}: {err_msg[:120]}")

                if _is_retryable_error(err_msg) and attempt < len(model_candidates) - 1:
                    # ë‹¤ìŒ fallback ëª¨ë¸ë¡œ ì¬ì‹œë„
                    next_label = model_candidates[attempt + 1][1]
                    print(f"[LLM] Error (retryable) â†’ falling back to {next_label}")
                    yield f"\n\n> âš ï¸ **{model_label}** ì„œë¹„ìŠ¤ ì¼ì‹œì  ì§€ì—° ë˜ëŠ” í•œë„ ì´ˆê³¼. **{next_label}** ìœ¼ë¡œ ìë™ ì „í™˜í•©ë‹ˆë‹¤..."
                    continue  # ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                elif _is_retryable_error(err_msg):
                    yield f"\n\n> ğŸš« **ëª¨ë“  ëª¨ë¸ì´ í˜„ì¬ ì§€ì—° ì¤‘ì´ê±°ë‚˜ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.** ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                elif "401" in err_msg or "authentication" in err_msg.lower():
                    yield f"\n\n> âš ï¸ **ì¸ì¦ ì˜¤ë¥˜**: API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. `.env` íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                else:
                    yield f"\n\n> âš ï¸ **ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ**: {err_msg[:200]}"
                return

    return StreamingResponse(generate(), media_type="text/plain")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
from langchain.prompts import PromptTemplate

MACRO_ANALYSIS_PROMPT = PromptTemplate(
    input_variables=["market_data", "news_summary", "bok_policy", "fed_policy", "macro_signals", "institutional_context", "liquidity_context", "user_query"],
    template="""
ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ë§¤í¬ë¡œ ì‹œì¥ì„ ê¹Šì´ í†µì°°í•˜ëŠ” ìµœê³ ì˜ ë§¤í¬ë¡œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë³µì¡í•œ ê¸€ë¡œë²Œ ê²½ì œì˜ íë¦„ì„ ë§ˆì¹˜ ì˜†ì—ì„œ ì´ì•¼ê¸°í•´ì£¼ë“¯ ì¹œì ˆí•˜ê³  ë‚ ì¹´ë¡­ê²Œ í’€ì–´ë‚´ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.

[ì ˆëŒ€ ê¸ˆì§€ â€” ë°˜ë“œì‹œ ì¤€ìˆ˜]
- "ì˜¤ê±´ì˜"ì´ë¼ëŠ” ì´ë¦„ì„ ë‹µë³€ ì–´ë””ì—ë„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- ìê¸°ì†Œê°œ ë¬¸ì¥(ì˜ˆ: "ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ, ì €ëŠ” â—‹â—‹ì…ë‹ˆë‹¤")ì„ ì‘ì„±í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- ë¶„ì„ ë‚´ìš©ìœ¼ë¡œ ê³§ë°”ë¡œ ì‹œì‘í•˜ì‹­ì‹œì˜¤.

[ì‚¬ìš©ìì˜ í•µì‹¬ ì§ˆë¬¸]: {user_query}

ìœ„ ì§ˆë¬¸ì— ì§‘ì¤‘í•˜ì—¬ ë¶„ì„í•˜ë˜, ë‹¨ìˆœí•œ ë°ì´í„° ë‚˜ì—´ì€ ì§€ì–‘í•˜ì„¸ìš”. ë°ì´í„°ë“¤ ì‚¬ì´ì˜ ì—°ê²°ê³ ë¦¬ë¥¼ ì°¾ì•„ í•œ í¸ì˜ ê¸ˆìœµ ì—ì„¸ì´ì²˜ëŸ¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

---

### [ë¶„ì„ ê°€ì´ë“œë¼ì¸]

**1. ë„ì…: ì˜¤ëŠ˜ì˜ ë§¤í¬ë¡œ í•œ ì¤„ ìš”ì•½**
- í˜„ì¬ ì‹œì¥ì„ ê´€í†µí•˜ëŠ” ê°€ì¥ í•µì‹¬ì ì¸ í‚¤ì›Œë“œë¥¼ ì¡ê³ , ì™œ ì§€ê¸ˆ ìš°ë¦¬ê°€ ê·¸ ë‹¨ì–´ì— ì£¼ëª©í•´ì•¼ í•˜ëŠ”ì§€ ì„¤ëª…í•˜ë©° ì‹œì‘í•˜ì„¸ìš”.

**2. ë³¸ë¡ : ì–½íŒ ì‹¤íƒ€ë˜ í’€ê¸° (ë°ì´í„°ì˜ ì„œì‚¬í™”)**
- ì œê³µëœ ì‹œì¥ ë°ì´í„°ì™€ ì£¼ìš” ê¸°ê´€ ì „ë§ì„ í™œìš©í•˜ë˜, ìŠ¤í† ë¦¬í…”ë§ìœ¼ë¡œ í’€ì–´ë‚´ì„¸ìš”.
- **ë¹„ìœ  í™œìš©:** ê²½ì œ ê°œë…ì„ ë¹„ìœ (ì˜ˆ: ìˆ˜ë„ê¼­ì§€, ì²´ì˜¨ê³„, ë¸Œë ˆì´í¬ ë“±)ë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ì„¸ìš”.
- **ë¬¸ë‹µ í˜•ì‹:** "ê·¸ëŸ¼ ì‹œì¥ì€ ì™œ ì´ë ‡ê²Œ ë°˜ì‘í–ˆì„ê¹Œìš”?", "ìš°ë¦¬ê°€ ë†“ì¹˜ê³  ìˆëŠ” ê±´ ì—†ì„ê¹Œìš”?" ê°™ì€ ì§ˆë¬¸ì„ ë˜ì§€ë©° ë…ìë¥¼ ì´ëŒì–´ ê°€ì„¸ìš”.
- **ê´€ì ì˜ ëŒ€ë¹„:** ì‹œì¥ì˜ ê¸°ëŒ€(í¬ë§ì‚¬í•­)ì™€ ì‹¤ì œ ë§¤í¬ë¡œ ì§€í‘œ ì‚¬ì´ì˜ ê´´ë¦¬ë¥¼ ë‚ ì¹´ë¡­ê²Œ ì§šì–´ì£¼ì„¸ìš”.

**3. ê²°ë¡ : í–¥í›„ ì‹œë‚˜ë¦¬ì˜¤ì™€ ëŒ€ì‘**
- ê²°ë¡ ì€ í•­ìƒ ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜ì´ì–´ì•¼ í•©ë‹ˆë‹¤. "ë¬´ì¡°ê±´ ì˜¤ë¥¸ë‹¤/ë‚´ë¦°ë‹¤"ê°€ ì•„ë‹ˆë¼, "A ìƒí™©ì´ ì˜¤ë©´ ì´ë ‡ê²Œ, B ìƒí™©ì´ ì˜¤ë©´ ì €ë ‡ê²Œ" ë°©ì‹ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”.
- í•œêµ­ íˆ¬ììë“¤ì—ê²Œ ê°€ì¥ ì¤‘ìš”í•œ ì›/ë‹¬ëŸ¬ í™˜ìœ¨ê³¼ êµ­ë‚´ ì£¼ì‹ì‹œì¥ì˜ ì—°ê²°ê³ ë¦¬ë¥¼ ë°˜ë“œì‹œ ì–¸ê¸‰í•˜ì„¸ìš”.

---

### [ì œê³µëœ ë°ì´í„°]
**1. ì‹œì¥ ì‹¤ì‹œê°„ ë°ì´í„°:** {market_data}
**2. ì£¼ìš” ë‰´ìŠ¤ ë° ì‹ í˜¸:** {news_summary} / {macro_signals}
**3. í†µí™” ì •ì±…:** í•œêµ­ì€í–‰({bok_policy}), ë¯¸ ì—°ì¤€({fed_policy})
**4. ë¯¸êµ­ ìœ ë™ì„± ì§€í‘œ (ì—°ì¤€/ì¬ë¬´ë¶€ ì‹¤ì‹œê°„):**
{liquidity_context}
**5. ê¸€ë¡œë²Œ IB RAG ë°ì´í„°:** {institutional_context}

---

### [ì‘ì„± í˜•ì‹]
- **ì–´ì¡°:** ì •ì¤‘í•˜ê³  ì¹œê·¼í•œ ê²½ì–´ì²´ (~í•©ë‹ˆë‹¤, ~ì´ì£ , ~ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤).
- **ë§ˆí¬ë‹¤ìš´:** í•µì‹¬ í‚¤ì›Œë“œëŠ” **êµµê²Œ** í‘œì‹œí•˜ê³ , ì¤‘ìš” ë³€ê³¡ì ì€ ## í—¤ë”ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.
- **ì¶œë ¥ êµ¬ì„±:**

  ## ğŸ–‹ï¸ ë§¤í¬ë¡œ ë¶„ì„: [ì œëª©]

  (ì„œìˆ í˜• ë¶„ì„ ë³¸ë¬¸ â€” ìê¸°ì†Œê°œ ì—†ì´ ë°”ë¡œ ë¶„ì„ ì‹œì‘)

  ## ğŸ“Œ í•µì‹¬ í¬ì¸íŠ¸ & ëŒ€ì‘ ì‹œë‚˜ë¦¬ì˜¤

  (ë¦¬ìŠ¤í¬ ë° ê¸°íšŒ ìš”ì¸ ì •ë¦¬)

  ---

  ## ğŸ“‹ ì°¸ì¡° ì¸í…”ë¦¬ì „ìŠ¤ ë¦¬í¬íŠ¸

  (ì´ì „ê³¼ ë™ì¼í•œ ì¹´ë“œ í˜•ì‹)
"""
)
